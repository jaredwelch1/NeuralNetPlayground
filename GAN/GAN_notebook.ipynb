{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN for MNIST digits\n",
    "\n",
    "Will load MNIST dataset and then train a GAN to generate hand written digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MNIST because tensorflow makes is super easy to use their dataset and this is an exploration notebook\"\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mnist.train\n",
    "train_images = train.images\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_im = train_images[randint(0,55000)].reshape([28,28])\n",
    "plt.imshow(rand_im, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Network (The A in GAN)\n",
    "\n",
    "We are going to use a simple convolutional neural network as our discriminator that takes in an image (28, 28, and grayscale so 1 input for color) and output whether the input is a real image or generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions that are useful when using tensorflow CNN\n",
    "def conv2d(x, W):\n",
    "    ''' creates a convoluational layer from input x and returns output layer '''\n",
    "    return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    ''' creates a pooling layer from input x and returns output layer from pooling '''\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x_image, reuse=False):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        # First conv layer with pooling after \n",
    "        w_conv1 = tf.get_variable('d_wconv1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_conv1 = tf.get_variable('d_bconv1', [32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n",
    "        h_pool1 = avg_pool_2x2(h_conv1)\n",
    "        \n",
    "        # Second conv layer with pooling\n",
    "        w_conv2 = tf.get_variable('d_wconv2', [5, 5, 32, 64])\n",
    "        b_conv2 = tf.get_variable('d_bconv2', [64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "        h_pool2 = avg_pool_2x2(h_conv2)\n",
    "        \n",
    "        # Fully connected layer \n",
    "        w_fc1 = tf.get_variable('d_wfc1', [7*7*64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc1 = tf.get_variable('d_bfc1', [1024], initializer=tf.constant_initializer(0))\n",
    "        h_pool2_flattened = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flattened, w_fc1) + b_fc1)\n",
    "        \n",
    "        # second fully connected layer\n",
    "        w_fc2 = tf.get_variable('d_wfc2', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc2 = tf.get_variable('d_bfc2', [1], initializer=tf.constant_initializer(0))\n",
    "        y_conv = (tf.matmul(h_fc1, w_fc2) + b_fc2)\n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator \n",
    "Structure of generator is similar to convolutional neural network like our discriminator, except its job is to upsample\n",
    "a random vector of noise into an image, and so it uses convolutional transpose function and then batch norm and relu on the output from the tranpose. The end result is a network which takes in a noise vector and generates a 28x28x1 image which matches the MNIST dataset input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim, reuse=False):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        g_dim = 64 # number of filters of first layer of generator \n",
    "        c_dim = 1 # dimension of color of output image\n",
    "        s = 28 # output dimension \n",
    "        \n",
    "        # get placeholders for upscale of input vector \n",
    "        s2 = 12\n",
    "        s4 = 6\n",
    "        s8 = 3\n",
    "        s16 = 2\n",
    "        \n",
    "        # input \n",
    "        h0 = tf.reshape(z, [batch_size, s16, s16, 25])\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        # h0 is [batch_size, 2, 2, 25]\n",
    "        \n",
    "        # first layer of deconv\n",
    "        output1_shape = [batch_size, s8, s8, g_dim*4]\n",
    "        w_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])],\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]],\n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        h_conv1 = tf.nn.conv2d_transpose(h0, w_conv1, output_shape=output1_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv1\n",
    "        # wrap in batch norm\n",
    "        h_conv1 = tf.contrib.layers.batch_norm(inputs=h_conv1, center=True, scale=True,\n",
    "                                               is_training=True, scope='g_bn1')\n",
    "        # wrap relu around the whole layer \n",
    "        h_conv1 = tf.nn.relu(h_conv1)\n",
    "        # output shape of [batch_size, 3, 3, 256] defined in output_shape1 \n",
    "        \n",
    "        # second deconv layer\n",
    "        output2_shape = [batch_size, s4, s4, g_dim*2]\n",
    "        w_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(h_conv1.get_shape()[-1])],\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]],\n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        h_conv2 = tf.nn.conv2d_transpose(h_conv1, w_conv2, output_shape=output2_shape,\n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv2\n",
    "        h_conv2 = tf.contrib.layers.batch_norm(inputs=h_conv2, center=True, scale=True,\n",
    "                                               is_training=True, scope='g_bn2')\n",
    "        h_conv2 = tf.nn.relu(h_conv2)\n",
    "        # out shape [ batch_size, 6, 6, 128 ]\n",
    "        \n",
    "        # third deconv layer\n",
    "        output3_shape = [batch_size, s2, s2, g_dim]\n",
    "        w_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(h_conv2.get_shape()[-1])],\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], \n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        h_conv3 = tf.nn.conv2d_transpose(h_conv2, w_conv3, output_shape=output3_shape,\n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n",
    "        h_conv3 = tf.contrib.layers.batch_norm(inputs=h_conv3, center=True, scale=True,\n",
    "                                               is_training=True, scope='g_bn3')\n",
    "        h_conv3 = tf.nn.relu(h_conv3)\n",
    "        # shape [ batch_size, 12, 12, 64 ]\n",
    "        \n",
    "        # final deconv layer\n",
    "        output4_shape = [batch_size, s, s, c_dim]\n",
    "        w_conv4 = tf.get_variable('g_wconv4', [5, 5, output4_shape[-1], int(h_conv3.get_shape()[-1])],\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]],\n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        h_conv4 = tf.nn.conv2d_transpose(h_conv3, w_conv4, output_shape=output4_shape,\n",
    "                                         strides=[1, 2, 2, 1], padding='VALID') + b_conv4\n",
    "        h_conv4 = tf.nn.tanh(h_conv4)\n",
    "    return h_conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a test of our generator to see if we get a valid greyscale image out of it from input vector \n",
    "sess = tf.Session()\n",
    "z_dims = 100\n",
    "z_test_placeholder = tf.placeholder(tf.float32, [None, z_dims])\n",
    "\n",
    "sample_image = generator(z_test_placeholder, 1, z_dims)\n",
    "test_z = np.random.normal(-1, 1, [1, z_dims])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "temp = (sess.run(sample_image, feed_dict={z_test_placeholder: test_z}))\n",
    "my_image = temp.squeeze()\n",
    "plt.imshow(my_image, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training \n",
    "\n",
    "The most difficult part of GAN is probably setting up loss functions correctly. We need loss functions that fit both networks, since GANs train two networks against each other it makes sense both would have loss we need to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "tf.reset_default_graph() # changed batch_size so just reset graph here before trying a new session\n",
    "\n",
    "sess = tf.Session()\n",
    "x_placeholder = tf.placeholder('float', shape=[None, 28, 28, 1]) # input images\n",
    "z_placeholder = tf.placeholder('float', shape=[None, z_dims]) # input for noise vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will hold dicsriminator prediction probabilities for real MNIST images\n",
    "Dx = discriminator(x_placeholder)\n",
    "\n",
    "# Will hold images generated by generator \n",
    "Gz = generator(z_placeholder, batch_size, z_dims)\n",
    "\n",
    "# hold discrimator probabilities for generated images\n",
    "Dg = discriminator(Gz, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "The goal of these two networks mean we need to maximize loss for \n",
    "- the generator and how well it can create new images that look real \n",
    "- the discriminator and how well it can distinguish between real and fake\n",
    "\n",
    "For the generator, we want to reach a label of 1 from the discriminator, which means we calculate loss between our Dg and an expected value of 1.\n",
    "\n",
    "For the discriminator, we want to reach correct labels, 0 for fake and 1 for MNIST digits. This means we will compute loss between Dg and 0 and Dx and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
