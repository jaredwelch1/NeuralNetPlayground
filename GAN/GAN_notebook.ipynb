{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN for MNIST digits\n",
    "\n",
    "Will load MNIST dataset and then train a GAN to generate hand written digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Use MNIST because tensorflow makes is super easy to use their dataset and this is an exploration notebook\"\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = mnist.train\n",
    "train_images = train.images\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e4342a49e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_im = train_images[randint(0,55000)].reshape([28,28])\n",
    "plt.imshow(rand_im, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Network (The A in GAN)\n",
    "\n",
    "We are going to use a simple convolutional neural network as our discriminator that takes in an image (28, 28, and grayscale so 1 input for color) and output whether the input is a real image or generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions that are useful when using tensorflow CNN\n",
    "def conv2d(x, W):\n",
    "    ''' creates a convoluational layer from input x and returns output layer '''\n",
    "    return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    ''' creates a pooling layer from input x and returns output layer from pooling '''\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x_image, reuse=False):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        # First conv layer with pooling after \n",
    "        w_conv1 = tf.get_variable('d_wconv1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_conv1 = tf.get_variable('d_bconv1', [32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n",
    "        h_pool1 = avg_pool_2x2(h_conv1)\n",
    "        \n",
    "        # Second conv layer with pooling\n",
    "        w_conv2 = tf.get_variable('d_wconv2', [5, 5, 32, 64])\n",
    "        b_conv2 = tf.get_variable('d_bconv2', [64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "        h_pool2 = avg_pool_2x2(h_conv2)\n",
    "        \n",
    "        # Fully connected layer \n",
    "        w_fc1 = tf.get_variable('d_wfc1', [7*7*64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc1 = tf.get_variable('d_bfc1', [1024], initializer=tf.constant_initializer(0))\n",
    "        h_pool2_flattened = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flattened, w_fc1) + b_fc1)\n",
    "        \n",
    "        # second fully connected layer\n",
    "        w_fc2 = tf.get_variable('d_wfc2', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc2 = tf.get_variable('d_bfc2', [1], initializer=tf.constant_initializer(0))\n",
    "        y_conv = (tf.matmul(h_fc1, w_fc2) + b_fc2)\n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator \n",
    "Structure of generator is similar to convolutional neural network like our discriminator, except its job is to upsample\n",
    "a random vector of noise into an image, and so it uses convolutional transpose function and then batch norm and relu on the output from the tranpose. The end result is a network which takes in a noise vector and generates a 28x28x1 image which matches the MNIST dataset input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim, reuse=False):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        g_dim = 64 # number of filters of first layer of generator \n",
    "        c_dim = 1 # dimension of color of output image\n",
    "        s = 28 # output dimension \n",
    "        \n",
    "        # get placeholders for upscale of input vector \n",
    "        s2 = 12\n",
    "        s4 = 6\n",
    "        s8 = 3\n",
    "        s16 = 2\n",
    "        \n",
    "        # input \n",
    "        h0 = tf.reshape(z, [batch_size, s16, s16, 25])\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        # h0 is [batch_size, 2, 2, 25]\n",
    "        \n",
    "        # first layer of deconv\n",
    "        output1_shape = [batch_size, s8, s8, g_dim*4]\n",
    "        w_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])],\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]],\n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        h_conv1 = tf.nn.conv2d_transpose(h0, w_conv1, output_shape=output1_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv1\n",
    "        # wrap in batch norm\n",
    "        h_conv1 = tf.contrib.layers.batch_norm(inputs=h_conv1, center=True, scale=True,\n",
    "                                               is_training=True, scope='g_bn1')\n",
    "        # wrap relu around the whole layer \n",
    "        h_conv1 = tf.nn.relu(h_conv1)\n",
    "        # output shape of [batch_size, 3, 3, 256] defined in output_shape1 \n",
    "        \n",
    "        # second deconv layer\n",
    "        output2_shape = [batch_size, s4, s4, g_dim*2]\n",
    "        w_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(h_conv1.get_shape()[-1])],\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]],\n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        h_conv2 = tf.nn.conv2d_transpose(h_conv1, w_conv2, output_shape=output2_shape,\n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv2\n",
    "        h_conv2 = tf.contrib.layers.batch_norm(inputs=h_conv2, center=True, scale=True,\n",
    "                                               is_training=True, scope='g_bn2')\n",
    "        h_conv2 = tf.nn.relu(h_conv2)\n",
    "        # out shape [ batch_size, 6, 6, 128 ]\n",
    "        \n",
    "        # third deconv layer\n",
    "        output3_shape = [batch_size, s2, s2, g_dim]\n",
    "        w_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(h_conv2.get_shape()[-1])],\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], \n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        h_conv3 = tf.nn.conv2d_transpose(h_conv2, w_conv3, output_shape=output3_shape,\n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n",
    "        h_conv3 = tf.contrib.layers.batch_norm(inputs=h_conv3, center=True, scale=True,\n",
    "                                               is_training=True, scope='g_bn3')\n",
    "        h_conv3 = tf.nn.relu(h_conv3)\n",
    "        # shape [ batch_size, 12, 12, 64 ]\n",
    "        \n",
    "        # final deconv layer\n",
    "        output4_shape = [batch_size, s, s, c_dim]\n",
    "        w_conv4 = tf.get_variable('g_wconv4', [5, 5, output4_shape[-1], int(h_conv3.get_shape()[-1])],\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]],\n",
    "                                  initializer=tf.constant_initializer(.1))\n",
    "        h_conv4 = tf.nn.conv2d_transpose(h_conv3, w_conv4, output_shape=output4_shape,\n",
    "                                         strides=[1, 2, 2, 1], padding='VALID') + b_conv4\n",
    "        h_conv4 = tf.nn.tanh(h_conv4)\n",
    "    return h_conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a test of our generator to see if we get a valid greyscale image out of it from input vector \n",
    "sess = tf.Session()\n",
    "z_dims = 100\n",
    "z_test_placeholder = tf.placeholder(tf.float32, [None, z_dims])\n",
    "\n",
    "sample_image = generator(z_test_placeholder, 1, z_dims)\n",
    "test_z = np.random.normal(-1, 1, [1, z_dims])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e43631d438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "temp = (sess.run(sample_image, feed_dict={z_test_placeholder: test_z}))\n",
    "my_image = temp.squeeze()\n",
    "plt.imshow(my_image, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training \n",
    "\n",
    "The most difficult part of GAN is probably setting up loss functions correctly. We need loss functions that fit both networks, since GANs train two networks against each other it makes sense both would have loss we need to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "tf.reset_default_graph() # changed batch_size so just reset graph here before trying a new session\n",
    "\n",
    "sess = tf.Session()\n",
    "x_placeholder = tf.placeholder('float', shape=[None, 28, 28, 1]) # input images\n",
    "z_placeholder = tf.placeholder('float', shape=[None, z_dims]) # input for noise vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will hold dicsriminator prediction probabilities for real MNIST images\n",
    "Dx = discriminator(x_placeholder)\n",
    "\n",
    "# Will hold images generated by generator \n",
    "Gz = generator(z_placeholder, BATCH_SIZE, z_dims)\n",
    "\n",
    "# hold discrimator probabilities for generated images\n",
    "Dg = discriminator(Gz, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "The goal of these two networks mean we need to maximize loss for \n",
    "- the generator and how well it can create new images that look real \n",
    "- the discriminator and how well it can distinguish between real and fake\n",
    "\n",
    "For the generator, we want to reach a label of 1 from the discriminator, which means we calculate loss between our Dg and an expected value of 1.\n",
    "\n",
    "For the discriminator, we want to reach correct labels, 0 for fake and 1 for MNIST digits. This means we will compute loss between Dg and 0 and Dx and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator loss\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                            logits=Dg, labels=tf.ones_like(Dg)))\n",
    "\n",
    "# discriminator loss combines real image loss and generator image loss\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                             logits=Dx, labels=tf.ones_like(Dx)))\n",
    "# loss for discriminator with generated images\n",
    "d_loss_gen = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                            logits=Dg, labels=tf.zeros_like(Dg)))\n",
    "\n",
    "# total discriminiator loss\n",
    "d_loss = d_loss_real + d_loss_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    "Now we create or optimizers. Note that when we train our generator, we do not need to change weights for our discriminator, so we need to make sure we have a list of the weights we need for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [v for v in tvars if 'd_' in v.name]\n",
    "g_vars = [v for v in tvars if 'g_' in v.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.train.AdamOptimizer()\n",
    "trainerD = adam.minimize(d_loss, var_list=d_vars)\n",
    "trainerG = adam.minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# make a func for training progress\n",
    "def _progress(count, total_count):\n",
    "    sys.stdout.write('\\r>> Training progress: %.1f%%' % (100*(count/total_count)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training progress: 100.0%"
     ]
    }
   ],
   "source": [
    "TRAIN_STEPS = 150000\n",
    "progress_bar_updates = 1000\n",
    "steps_per_update = TRAIN_STEPS // progress_bar_updates\n",
    "updates_printed = 0\n",
    "for _ in range(TRAIN_STEPS):\n",
    "    # get a set of noise vectors\n",
    "    z_batch = np.random.normal(-1, 1, size=[BATCH_SIZE, z_dims])\n",
    "    img_batch = train.next_batch(BATCH_SIZE)\n",
    "    real_image_batch = np.reshape(img_batch[0], [BATCH_SIZE, 28, 28, 1])\n",
    "    \n",
    "    # update discriminator NN\n",
    "    __, dLoss = sess.run([trainerD, d_loss], feed_dict={z_placeholder:z_batch, x_placeholder: real_image_batch})\n",
    "    \n",
    "    # feed generator and update it\n",
    "    __, gLoss = sess.run([trainerG, g_loss], feed_dict={z_placeholder:z_batch})\n",
    "    \n",
    "    if _ % steps_per_update == 0:\n",
    "        _progress(updates_printed, progress_bar_updates)\n",
    "        updates_printed += 1\n",
    "_progress(progress_bar_updates, progress_bar_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw3xsCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e4362dff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampler_gen = generator(z_placeholder, 1, z_dims, reuse=True)\n",
    "z_batch = np.random.normal(-1, 1, [1, z_dims])\n",
    "temp = sess.run(sampler_gen, feed_dict={z_placeholder: z_batch})\n",
    "img = temp.squeeze()\n",
    "plt.imshow(img, cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely an improvement from the initial generator, looking almost like a 9. For a starter GAN, worked decently after a long amount of training. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
