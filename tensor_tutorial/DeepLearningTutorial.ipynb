{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# extract data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple softmax regression model creation \n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "# cross entropy for training \n",
    "c_e = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(c_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the tensorflow session and train the model\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# for reference, the _ here indicates that the loop variable is not needed and tells python not to care about holding it\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy of our created and trained model\n",
    "\n",
    "# tf.argmax returns the index of the highest entry in a tensor along some axis \n",
    "# (gives us the soft max values from the predicted values and the one-hot values from the correct labels)\n",
    "#\n",
    "# this gives us back the indices where correct prediction occurs and incorrect\n",
    "# for example\n",
    "# [correct, correct, incorrect] returns as [1, 1, 0]\n",
    "# this array can be used to calc the overall percentage \n",
    "#\n",
    "# TLDR;\n",
    "# Converts from one-hot form of data into a simple class labels list for both predicted and correct datasets\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918\n"
     ]
    }
   ],
   "source": [
    "# Gauge the accuracy of the model against the test data\n",
    "\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving upon the simple one layer NN structure to improve accuracy\n",
    "\n",
    "Simple one layer NN gets ~92% accuracy with the MNIST handwritten digits. In order to improve this accuracy, creating a convolutional NN which captures visual features in a more sophisticated way and is better suited for image deep learning tasks than simple softmax. \n",
    "\n",
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some helping functions for weight and bias creation for our NN\n",
    "def weight_variable(shape):\n",
    "    init = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    init = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create helper functions for convolution and pooling. \n",
    "# For more information about CNN:\n",
    "# https://en.wikipedia.org/wiki/Convolutional_neural_network\n",
    "\n",
    "# This helper function lets us encapsulate our stride and padding settings basically and just focus on shape\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# pooling for every 2x2 space into 1 output based on the max value in the 2x2 square\n",
    "# Example:\n",
    "#     [[1, 2],\n",
    "#     [3, 4]]\n",
    "#     would return [4]\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping of input images. Input images 28*28. Flatten them. \n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "x_flat = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# First layer will be 5*5 patches with 1 input channel (greyscale images). Output of 32 features for each patch\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# create first layer of convolution\n",
    "# relu is a type of activation function \n",
    "# https://en.wikipedia.org/wiki/Activation_function\n",
    "h_conv1 = tf.nn.relu(conv2d(x_flat, W_conv1) + b_conv1)\n",
    "\n",
    "# pooling follows first layer \n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# second layer\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add densely connected layer at the end before softmax \n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop-out applied before the readout layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final softmax output layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, training accuracy 0.16\n",
      "Step 1000, training accuracy 0.94\n",
      "Step 2000, training accuracy 1\n",
      "Step 3000, training accuracy 0.96\n",
      "Step 4000, training accuracy 1\n",
      "Step 5000, training accuracy 1\n",
      "Step 6000, training accuracy 0.98\n",
      "Step 7000, training accuracy 0.98\n",
      "Step 8000, training accuracy 1\n",
      "Step 9000, training accuracy 0.98\n",
      "Step 10000, training accuracy 1\n",
      "Step 11000, training accuracy 0.98\n",
      "Step 12000, training accuracy 1\n",
      "Step 13000, training accuracy 1\n",
      "Step 14000, training accuracy 1\n",
      "Step 15000, training accuracy 1\n",
      "Step 16000, training accuracy 1\n",
      "Step 17000, training accuracy 1\n",
      "Step 18000, training accuracy 1\n",
      "Step 19000, training accuracy 1\n"
     ]
    }
   ],
   "source": [
    "c_e = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(c_e)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(20000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(50)\n",
    "    if i % 1000 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch_xs, y_:batch_ys, keep_prob: 1.0\n",
    "        })\n",
    "        print(\"Step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x:batch_xs, y_:batch_ys, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy: %g'%accuracy.eval(feed_dict={x: mnist.test.images, y_:mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
